import os
import pandas as pd
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

def search_in_chunk(chunk, file_path, keywords, search_mode="row"):
    """Search for keywords in either specific cells or entire rows."""
    results = []
    for index, row in chunk.iterrows():
        if search_mode == "row":
            # Combine all values in the row and search for keywords
            row_values = " ".join(str(value) for value in row.values)
            if any(re.search(keyword, row_values, re.IGNORECASE) for keyword in keywords):
                results.append((file_path, index, row.to_dict()))  # Add the entire row as a dictionary
        elif search_mode == "cell":
            # Check individual cells for matches
            for column, value in row.items():
                for keyword in keywords:
                    if re.search(keyword, str(value), re.IGNORECASE):
                        results.append((file_path, index, column, value))  # Ensure 4 values are returned
    return results

#####################################################
def process_file(file_path, keywords, chunk_size=10, search_mode="row"):
    """Process a file by dividing it into chunks and searching each chunk."""
    results = []
    try:
        df = pd.read_excel(file_path) if file_path.endswith('.xlsx') else pd.read_csv(file_path)
        total_rows = len(df)
        chunks = [df.iloc[i:i + chunk_size] for i in range(0, total_rows, chunk_size)]

        # Create threads for chunks
        with ThreadPoolExecutor(max_workers=min(len(chunks), 4)) as executor:
            future_to_chunk = {
                executor.submit(search_in_chunk, chunk, file_path, keywords, search_mode): chunk
                for chunk in chunks
            }
            for future in future_to_chunk:
                chunk_results = future.result()
                if chunk_results:
                    results.extend(chunk_results)
    except Exception as e:
        print(f"Error processing file {file_path}: {e}")
    return results

########################################
def process_files_dynamically(file_list, keywords, search_mode="row"):
    """Process multiple files dynamically based on their size."""
    all_results = []

    # Calculate max threads based on number and size of files
    total_chunks = 0
    for file in file_list:
        df = pd.read_excel(file) if file.endswith('.xlsx') else pd.read_csv(file)
        total_chunks += len(df) // 10 + 1

    max_threads = min(total_chunks, os.cpu_count() * 2)  # Set a sensible limit based on system cores
    print(f"Using up to {max_threads} threads.")

    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        future_to_file = {
            executor.submit(process_file, file, keywords, search_mode=search_mode): file
            for file in file_list
        }
        for future in future_to_file:  # as_completed is not necessary for this scenario
            try:
                file_results = future.result()
                if file_results:
                    all_results.extend(file_results)
            except Exception as e:
                print(f"Error processing file {future_to_file[future]}: {e}")

    return all_results

####################################################
# def generate_excel_file(results, output_path="search_results.xlsx"):
#     """Generate an Excel file from the search results."""
#     try:
#         # Prepare data for the Excel file
#         data = [{
#             "File": file,
#             "Row": row,
#             "Column": column,
#             "Value": value
#         } for file, row, column, value in results]

#         # Create a DataFrame and write to Excel
#         df = pd.DataFrame(data)
#         df.to_excel(output_path, index=False)
#         print(f"Results saved to {output_path}")
#     except Exception as e:
#         print(f"Error generating Excel file: {e}")

def generate_excel_file(results, output_path="search_results.xlsx", search_mode="row"):
    """Generate an Excel file from the search results."""
    try:
        # Prepare data for the Excel file
        rows = []
        if search_mode == "row":
            for file, index, row_data in results:
                row_data["File"] = file
                row_data["Row"] = index
                rows.append(row_data)
        elif search_mode == "cell":
            for file, row, column, value in results:
                rows.append({"File": file, "Row": row, "Column": column, "Value": value})

        # Create a DataFrame and write to Excel
        df = pd.DataFrame(rows)
        df.to_excel(output_path, index=False)
        print(f"Results saved to {output_path}")
    except Exception as e:
        print(f"Error generating Excel file: {e}")

####################################################
# if __name__ == "__main__":
#     # Prompt user for input
#     print("Enter the paths to Excel or CSV files, separated by commas (e.g., file1.xlsx,file2.csv):")
#     input_files = input().strip()
#     file_list = [file.strip() for file in input_files.split(',') if os.path.isfile(file)]
#     print("Enter the keywords to search for, separated by commas (e.g., keyword1,keyword2):")
#     keywords = [keyword.strip() for keyword in input().split(',')]

#     print("Choose search mode: 'row' to search entire rows, 'cell' to search specific cells.")
#     search_mode = input().strip().lower()
#     if search_mode not in ["row", "cell"]:
#         print("Invalid search mode. Defaulting to 'row'.")
#         search_mode = "row"

#     if not file_list or not keywords:
#         print("Invalid input. Please provide files and keywords.")
#         exit(1)

#     print(f"\nSearching for keywords in {search_mode} mode...")
#     results = process_files_dynamically(file_list, keywords)

#     if results:
#         print("\nSearch Results:")
#         if search_mode == "row":
#             for file, row, data in results:
#                 print(f"File: {file}, Row: {row}, Data: {data}")
#         elif search_mode == "cell":
#             for file, row, column, value in results:
#                 print(f"File: {file}, Row: {row}, Column: {column}, Match: {value}")

#         # Generate Excel file from results
#         generate_excel_file(results, search_mode=search_mode)
#     else:
#         print("No matches found.")

if __name__ == "__main__":
    # ... (prompt input code remains the same)
    # Prompt user for input
    print("Enter the paths to Excel or CSV files, separated by commas (e.g., file1.xlsx,file2.csv):")
    input_files = input().strip()
    file_list = [file.strip() for file in input_files.split(',') if os.path.isfile(file)]
    print("Enter the keywords to search for, separated by commas (e.g., keyword1,keyword2):")
    keywords = [keyword.strip() for keyword in input().split(',')]

    print("Choose search mode: 'row' to search entire rows, 'cell' to search specific cells.")
    search_mode = input().strip().lower()
    if search_mode not in ["row", "cell"]:
        print("Invalid search mode. Defaulting to 'row'.")
        search_mode = "row"

    if not file_list or not keywords:
        print("Invalid input. Please provide files and keywords.")
        exit(1)
    
    print(f"\nSearching for keywords in {search_mode} mode...")
    results = process_files_dynamically(file_list, keywords, search_mode=search_mode)

    if results:
        print("\nSearch Results:")
        if search_mode == "row":
            for file, row, data in results:
                print(f"File: {file}, Row: {row}, Data: {data}")
        elif search_mode == "cell":
            for file, row, column, value in results:  # Now matches the return structure
                print(f"File: {file}, Row: {row}, Column: {column}, Match: {value}")

        # Generate Excel file from results
        generate_excel_file(results, search_mode=search_mode)
    else:
        print("No matches found.")